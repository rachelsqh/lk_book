<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>内存在进程中的表示 &mdash; Rachel&#39;s E-book 1.0 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Rachel's E-book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../os_base/index.html">linux 操作系统概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lk_devel/index.html">linux 内核开发基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../x86_kernel_base.html">linux X86内核基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lk_code/index.html">linux 内核基础代码分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pm.html">电源管理框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpu.html">cpu管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../driver.html">设备驱动</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ps.html">进程管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mem.html">内存管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fs.html">文件系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sec.html">linux 内核安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../yocto_kernel.html">yocto uboot与内核模块、内核开发总结</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../uboot.html">uboot理解</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dot.html">dot画图</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Rachel's E-book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>内存在进程中的表示</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/lk_code_base/kernel_mem/mem_kernel_arch.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="id1">
<h1>内存在进程中的表示<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>描述平台：
- kernel:5.14
- hw:x86</p>
<div class="section" id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>内核页表：swapper_pg_dir:内核页表目录（注意，这只代表地址空间，剩下的硬件都可以分配：这个要更深入理解一下，vmalloc的理解很重要）</p></li>
<li><p>应用页表：task-&gt;mm:注意，只有应用进程有struct mm_struct 结构，其中的mm-&gt;pgd指向进程的页表目录，在应用进程加载应用软件时（执行exec系统调用）为进程分配struct mm_struct结构，并在为mm_struct 结构分配也表目录（pgd成员）时首先复制内核也表到pgd(swapper_pg_dir),然后加载应用软件时分配应用空间并为其建立也表映射（pgd)。也就是说所有进程的页表目录都包含相同的内核映射。针对内核线程并没有单独的mm结构，当切换到一个内核线程时，不需要切换内存空间（x86中CR3寄存器切换），直接使用上一个进程的CR3的值（此时能调用call helper吗？）。</p></li>
<li><p>更明确mm 和 active_mm成员概念及应用场景：</p></li>
<li><p>vmalloc 这部分的处理方式：</p></li>
</ul>
</div>
<div class="section" id="id3">
<h2>结构描述<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>内存成员</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id11">
<div class="code-block-caption"><span class="caption-text">struct_task –&gt; mm</span><a class="headerlink" href="#id11" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="nc">task_struct</span> <span class="p">{</span>
<span class="p">......</span>
     <span class="k">struct</span> <span class="nc">mm_struct</span>                <span class="o">*</span><span class="n">mm</span><span class="p">;</span>
<span class="hll">     <span class="k">struct</span> <span class="nc">mm_struct</span>                <span class="o">*</span><span class="n">active_mm</span><span class="p">;</span>
</span><span class="hll"><span class="p">......</span>
</span><span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<ul class="simple">
<li><p>我们看struct mm_struct 结构：</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">struct mm_struct 定义</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190</pre></div></td><td class="code"><div class="highlight"><pre><span></span>   <span class="k">struct</span> <span class="nc">mm_struct</span> <span class="p">{</span>
   	<span class="k">struct</span> <span class="p">{</span>
   		<span class="k">struct</span> <span class="nc">vm_area_struct</span> <span class="o">*</span><span class="n">mmap</span><span class="p">;</span>		<span class="cm">/* list of VMAs:应用内存空间 */</span>
   		<span class="k">struct</span> <span class="nc">rb_root</span> <span class="n">mm_rb</span><span class="p">;</span>
<span class="hll">		<span class="n">u64</span> <span class="n">vmacache_seqnum</span><span class="p">;</span>                   <span class="cm">/* per-thread vmacache */</span>
</span><span class="cp">#ifdef CONFIG_MMU</span>
<span class="hll">		<span class="kt">unsigned</span> <span class="nf">long</span> <span class="p">(</span><span class="o">*</span><span class="n">get_unmapped_area</span><span class="p">)</span> <span class="p">(</span><span class="k">struct</span> <span class="nc">file</span> <span class="o">*</span><span class="n">filp</span><span class="p">,</span>
</span><span class="hll">				<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">,</span>
</span><span class="hll">				<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pgoff</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">);</span>
</span><span class="hll"><span class="cp">#endif</span>
</span><span class="hll">		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mmap_base</span><span class="p">;</span>	<span class="cm">/* base of mmap area */</span>
</span><span class="hll">		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mmap_legacy_base</span><span class="p">;</span>	<span class="cm">/* base of mmap area in bottom-up allocations */</span>
</span><span class="cp">#ifdef CONFIG_HAVE_ARCH_COMPAT_MMAP_BASES</span>
		<span class="cm">/* Base addresses for compatible mmap() */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mmap_compat_base</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mmap_compat_legacy_base</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">task_size</span><span class="p">;</span>	<span class="cm">/* size of task vm space */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">highest_vm_end</span><span class="p">;</span>	<span class="cm">/* highest vma end address */</span>
		<span class="n">pgd_t</span> <span class="o">*</span> <span class="n">pgd</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_MEMBARRIER</span>
		<span class="cm">/**</span>
<span class="cm">		 * @membarrier_state: Flags controlling membarrier behavior.</span>
<span class="cm">		 *</span>
<span class="cm">		 * This field is close to @pgd to hopefully fit in the same</span>
<span class="cm">		 * cache-line, which needs to be touched by switch_mm().</span>
<span class="cm">		 */</span>
		<span class="n">atomic_t</span> <span class="n">membarrier_state</span><span class="p">;</span>
<span class="cp">#endif</span>

		<span class="cm">/**</span>
<span class="cm">		 * @mm_users: The number of users including userspace.</span>
<span class="cm">		 *</span>
<span class="cm">		 * Use mmget()/mmget_not_zero()/mmput() to modify. When this</span>
<span class="cm">		 * drops to 0 (i.e. when the task exits and there are no other</span>
<span class="cm">		 * temporary reference holders), we also release a reference on</span>
<span class="cm">		 * @mm_count (which may then free the &amp;struct mm_struct if</span>
<span class="cm">		 * @mm_count also drops to 0).</span>
<span class="cm">		 */</span>
		<span class="n">atomic_t</span> <span class="n">mm_users</span><span class="p">;</span>

		<span class="cm">/**</span>
<span class="cm">		 * @mm_count: The number of references to &amp;struct mm_struct</span>
<span class="cm">		 * (@mm_users count as 1).</span>
<span class="cm">		 *</span>
<span class="cm">		 * Use mmgrab()/mmdrop() to modify. When this drops to 0, the</span>
<span class="cm">		 * &amp;struct mm_struct is freed.</span>
<span class="cm">		 */</span>
		<span class="n">atomic_t</span> <span class="n">mm_count</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_MMU</span>
		<span class="n">atomic_long_t</span> <span class="n">pgtables_bytes</span><span class="p">;</span>	<span class="cm">/* PTE page table pages */</span>
<span class="cp">#endif</span>
		<span class="kt">int</span> <span class="n">map_count</span><span class="p">;</span>			<span class="cm">/* number of VMAs */</span>

		<span class="n">spinlock_t</span> <span class="n">page_table_lock</span><span class="p">;</span> <span class="cm">/* Protects page tables and some</span>
<span class="cm">					     * counters</span>
<span class="cm">					     */</span>
		<span class="cm">/*</span>
<span class="cm">		 * With some kernel config, the current mmap_lock&#39;s offset</span>
<span class="cm">		 * inside &#39;mm_struct&#39; is at 0x120, which is very optimal, as</span>
<span class="cm">		 * its two hot fields &#39;count&#39; and &#39;owner&#39; sit in 2 different</span>
<span class="cm">		 * cachelines,  and when mmap_lock is highly contended, both</span>
<span class="cm">		 * of the 2 fields will be accessed frequently, current layout</span>
<span class="cm">		 * will help to reduce cache bouncing.</span>
<span class="cm">		 *</span>
<span class="cm">		 * So please be careful with adding new fields before</span>
<span class="cm">		 * mmap_lock, which can easily push the 2 fields into one</span>
<span class="cm">		 * cacheline.</span>
<span class="cm">		 */</span>
		<span class="k">struct</span> <span class="nc">rw_semaphore</span> <span class="n">mmap_lock</span><span class="p">;</span>

		<span class="k">struct</span> <span class="nc">list_head</span> <span class="n">mmlist</span><span class="p">;</span> <span class="cm">/* List of maybe swapped mm&#39;s.	These</span>
<span class="cm">					  * are globally strung together off</span>
<span class="cm">					  * init_mm.mmlist, and are protected</span>
<span class="cm">					  * by mmlist_lock</span>
<span class="cm">					  */</span>


		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">hiwater_rss</span><span class="p">;</span> <span class="cm">/* High-watermark of RSS usage */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">hiwater_vm</span><span class="p">;</span>  <span class="cm">/* High-water virtual memory usage */</span>

		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">total_vm</span><span class="p">;</span>	   <span class="cm">/* Total pages mapped */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">locked_vm</span><span class="p">;</span>   <span class="cm">/* Pages that have PG_mlocked set */</span>
		<span class="n">atomic64_t</span>    <span class="n">pinned_vm</span><span class="p">;</span>   <span class="cm">/* Refcount permanently increased */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">data_vm</span><span class="p">;</span>	   <span class="cm">/* VM_WRITE &amp; ~VM_SHARED &amp; ~VM_STACK */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">exec_vm</span><span class="p">;</span>	   <span class="cm">/* VM_EXEC &amp; ~VM_WRITE &amp; ~VM_STACK */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">stack_vm</span><span class="p">;</span>	   <span class="cm">/* VM_STACK */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">def_flags</span><span class="p">;</span>

		<span class="cm">/**</span>
<span class="cm">		 * @write_protect_seq: Locked when any thread is write</span>
<span class="cm">		 * protecting pages mapped by this mm to enforce a later COW,</span>
<span class="cm">		 * for instance during page table copying for fork().</span>
<span class="cm">		 */</span>
		<span class="n">seqcount_t</span> <span class="n">write_protect_seq</span><span class="p">;</span>

		<span class="n">spinlock_t</span> <span class="n">arg_lock</span><span class="p">;</span> <span class="cm">/* protect the below fields */</span>

		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start_code</span><span class="p">,</span> <span class="n">end_code</span><span class="p">,</span> <span class="n">start_data</span><span class="p">,</span> <span class="n">end_data</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start_brk</span><span class="p">,</span> <span class="n">brk</span><span class="p">,</span> <span class="n">start_stack</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">arg_start</span><span class="p">,</span> <span class="n">arg_end</span><span class="p">,</span> <span class="n">env_start</span><span class="p">,</span> <span class="n">env_end</span><span class="p">;</span>

		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">saved_auxv</span><span class="p">[</span><span class="n">AT_VECTOR_SIZE</span><span class="p">];</span> <span class="cm">/* for /proc/PID/auxv */</span>

		<span class="cm">/*</span>
<span class="cm">		 * Special counters, in some configurations protected by the</span>
<span class="cm">		 * page_table_lock, in other configurations by being atomic.</span>
<span class="cm">		 */</span>
		<span class="k">struct</span> <span class="nc">mm_rss_stat</span> <span class="n">rss_stat</span><span class="p">;</span>

		<span class="k">struct</span> <span class="nc">linux_binfmt</span> <span class="o">*</span><span class="n">binfmt</span><span class="p">;</span>

		<span class="cm">/* Architecture-specific MM context */</span>
		<span class="n">mm_context_t</span> <span class="n">context</span><span class="p">;</span>

		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span> <span class="cm">/* Must use atomic bitops to access */</span>

		<span class="k">struct</span> <span class="nc">core_state</span> <span class="o">*</span><span class="n">core_state</span><span class="p">;</span> <span class="cm">/* coredumping support */</span>

<span class="cp">#ifdef CONFIG_AIO</span>
		<span class="n">spinlock_t</span>			<span class="n">ioctx_lock</span><span class="p">;</span>
		<span class="k">struct</span> <span class="nc">kioctx_table</span> <span class="n">__rcu</span>	<span class="o">*</span><span class="n">ioctx_table</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_MEMCG</span>
		<span class="cm">/*</span>
<span class="cm">		 * &quot;owner&quot; points to a task that is regarded as the canonical</span>
<span class="cm">		 * user/owner of this mm. All of the following must be true in</span>
<span class="cm">		 * order for it to be changed:</span>
<span class="cm">		 *</span>
<span class="cm">		 * current == mm-&gt;owner</span>
<span class="cm">		 * current-&gt;mm != mm</span>
<span class="cm">		 * new_owner-&gt;mm == mm</span>
<span class="cm">		 * new_owner-&gt;alloc_lock is held</span>
<span class="cm">		 */</span>
		<span class="k">struct</span> <span class="nc">task_struct</span> <span class="n">__rcu</span> <span class="o">*</span><span class="n">owner</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="k">struct</span> <span class="nc">user_namespace</span> <span class="o">*</span><span class="n">user_ns</span><span class="p">;</span>

		<span class="cm">/* store ref to file /proc/&lt;pid&gt;/exe symlink points to */</span>
		<span class="k">struct</span> <span class="nc">file</span> <span class="n">__rcu</span> <span class="o">*</span><span class="n">exe_file</span><span class="p">;</span>
<span class="cp">#ifdef CONFIG_MMU_NOTIFIER</span>
		<span class="k">struct</span> <span class="nc">mmu_notifier_subscriptions</span> <span class="o">*</span><span class="n">notifier_subscriptions</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS</span>
		<span class="n">pgtable_t</span> <span class="n">pmd_huge_pte</span><span class="p">;</span> <span class="cm">/* protected by page_table_lock */</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_NUMA_BALANCING</span>
		<span class="cm">/*</span>
<span class="cm">		 * numa_next_scan is the next time that the PTEs will be marked</span>
<span class="cm">		 * pte_numa. NUMA hinting faults will gather statistics and</span>
<span class="cm">		 * migrate pages to new nodes if necessary.</span>
<span class="cm">		 */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">numa_next_scan</span><span class="p">;</span>

		<span class="cm">/* Restart point for scanning and setting pte_numa */</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">numa_scan_offset</span><span class="p">;</span>

		<span class="cm">/* numa_scan_seq prevents two threads setting pte_numa */</span>
		<span class="kt">int</span> <span class="n">numa_scan_seq</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="cm">/*</span>
<span class="cm">		 * An operation with batched TLB flushing is going on. Anything</span>
<span class="cm">		 * that can move process memory needs to flush the TLB when</span>
<span class="cm">		 * moving a PROT_NONE or PROT_NUMA mapped page.</span>
<span class="cm">		 */</span>
		<span class="n">atomic_t</span> <span class="n">tlb_flush_pending</span><span class="p">;</span>
<span class="cp">#ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</span>
		<span class="cm">/* See flush_tlb_batched_pending() */</span>
		<span class="kt">bool</span> <span class="n">tlb_flush_batched</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="k">struct</span> <span class="nc">uprobes_state</span> <span class="n">uprobes_state</span><span class="p">;</span>
<span class="cp">#ifdef CONFIG_HUGETLB_PAGE</span>
		<span class="n">atomic_long_t</span> <span class="n">hugetlb_usage</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="k">struct</span> <span class="nc">work_struct</span> <span class="n">async_put_work</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_IOMMU_SUPPORT</span>
		<span class="n">u32</span> <span class="n">pasid</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="p">}</span> <span class="n">__randomize_layout</span><span class="p">;</span>  <span class="c1">//struct end</span>

	<span class="cm">/*</span>
<span class="cm">	 * The mm_cpumask needs to be at the end of mm_struct, because it</span>
<span class="cm">	 * is dynamically sized based on nr_cpu_ids.</span>
<span class="cm">	 */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">cpu_bitmap</span><span class="p">[];</span>
    <span class="p">};</span>

</pre></div>
</td></tr></table></div>
</div>
<ul class="simple">
<li><p>struct vm_area_struct 结构描述</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">struct vm_area_struct 定义</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/*</span>
<span class="cm"> * This struct describes a virtual memory area. There is one of these</span>
<span class="cm"> * per VM-area/task. A VM area is any part of the process virtual memory</span>
<span class="cm"> * space that has a special rule for the page-fault handlers (ie a shared</span>
<span class="hll"><span class="cm"> * library, the executable area etc).</span>
</span><span class="cm"> */</span>
<span class="hll"><span class="k">struct</span> <span class="nc">vm_area_struct</span> <span class="p">{</span>
</span><span class="hll">	<span class="cm">/* The first cache line has the info for VMA tree walking. */</span>
</span><span class="hll">
</span><span class="hll">	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_start</span><span class="p">;</span>		<span class="cm">/* Our start address within vm_mm. */</span>
</span><span class="hll">	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_end</span><span class="p">;</span>		<span class="cm">/* The first byte after our end address</span>
</span><span class="hll"><span class="cm">					   within vm_mm. */</span>
</span>
	<span class="cm">/* linked list of VM areas per task, sorted by address */</span>
	<span class="k">struct</span> <span class="nc">vm_area_struct</span> <span class="o">*</span><span class="n">vm_next</span><span class="p">,</span> <span class="o">*</span><span class="n">vm_prev</span><span class="p">;</span>

	<span class="k">struct</span> <span class="nc">rb_node</span> <span class="n">vm_rb</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Largest free memory gap in bytes to the left of this VMA.</span>
<span class="cm">	 * Either between this VMA and vma-&gt;vm_prev, or between one of the</span>
<span class="cm">	 * VMAs below us in the VMA rbtree and its -&gt;vm_prev. This helps</span>
<span class="cm">	 * get_unmapped_area find a free area of the right size.</span>
<span class="cm">	 */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">rb_subtree_gap</span><span class="p">;</span>

	<span class="cm">/* Second cache line starts here. */</span>

	<span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">vm_mm</span><span class="p">;</span>	<span class="cm">/* The address space we belong to. */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Access permissions of this VMA.</span>
<span class="cm">	 * See vmf_insert_mixed_prot() for discussion.</span>
<span class="cm">	 */</span>
	<span class="n">pgprot_t</span> <span class="n">vm_page_prot</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_flags</span><span class="p">;</span>		<span class="cm">/* Flags, see mm.h. */</span>

	<span class="cm">/*</span>
<span class="cm">	 * For areas with an address space and backing store,</span>
<span class="cm">	 * linkage into the address_space-&gt;i_mmap interval tree.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="nc">rb_node</span> <span class="n">rb</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">rb_subtree_last</span><span class="p">;</span>
	<span class="p">}</span> <span class="n">shared</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * A file&#39;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma</span>
<span class="cm">	 * list, after a COW of one of the file pages.	A MAP_SHARED vma</span>
<span class="cm">	 * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack</span>
<span class="cm">	 * or brk vma (with NULL file) can only be in an anon_vma list.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="nc">list_head</span> <span class="n">anon_vma_chain</span><span class="p">;</span> <span class="cm">/* Serialized by mmap_lock &amp;</span>
<span class="cm">					  * page_table_lock */</span>
	<span class="k">struct</span> <span class="nc">anon_vma</span> <span class="o">*</span><span class="n">anon_vma</span><span class="p">;</span>	<span class="cm">/* Serialized by page_table_lock */</span>

	<span class="cm">/* Function pointers to deal with this struct. */</span>
	<span class="k">const</span> <span class="k">struct</span> <span class="nc">vm_operations_struct</span> <span class="o">*</span><span class="n">vm_ops</span><span class="p">;</span>

	<span class="cm">/* Information about our backing store: */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_pgoff</span><span class="p">;</span>		<span class="cm">/* Offset (within vm_file) in PAGE_SIZE</span>
<span class="cm">					   units */</span>
	<span class="k">struct</span> <span class="nc">file</span> <span class="o">*</span> <span class="n">vm_file</span><span class="p">;</span>		<span class="cm">/* File we map to (can be NULL). */</span>
	<span class="kt">void</span> <span class="o">*</span> <span class="n">vm_private_data</span><span class="p">;</span>		<span class="cm">/* was vm_pte (shared mem) */</span>

<span class="cp">#ifdef CONFIG_SWAP</span>
	<span class="n">atomic_long_t</span> <span class="n">swap_readahead_info</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#ifndef CONFIG_MMU</span>
	<span class="k">struct</span> <span class="nc">vm_region</span> <span class="o">*</span><span class="n">vm_region</span><span class="p">;</span>	<span class="cm">/* NOMMU mapping region */</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_NUMA</span>
	<span class="k">struct</span> <span class="nc">mempolicy</span> <span class="o">*</span><span class="n">vm_policy</span><span class="p">;</span>	<span class="cm">/* NUMA policy for the VMA */</span>
<span class="cp">#endif</span>
	<span class="k">struct</span> <span class="nc">vm_userfaultfd_ctx</span> <span class="n">vm_userfaultfd_ctx</span><span class="p">;</span>
<span class="p">}</span> <span class="n">__randomize_layout</span><span class="p">;</span>
</pre></div>
</td></tr></table></div>
</div>
<p>struct vm_area_struct代表一块连续虚拟地址空间映射。</p>
<dl>
<dt>以X86为例，看vma与物理页面的关系</dt><dd><p>mm_struct –&gt; pgd_t * pgd;</p>
<p>现在我们看新建进程时对内存的处理：（fork –&gt; kernel_clone)</p>
</dd>
</dl>
<div class="literal-block-wrapper docutils container" id="fork">
<div class="code-block-caption"><span class="caption-text">fork –&gt; kernel_clone()实现</span><a class="headerlink" href="#fork" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/*</span>
<span class="cm"> *  Ok, this is the main fork-routine.</span>
<span class="cm"> *</span>
<span class="cm"> * It copies the process, and if successful kick-starts</span>
<span class="hll"><span class="cm"> * it and waits for it to finish using the VM if required.</span>
</span><span class="cm"> *</span>
<span class="hll"><span class="cm"> * args-&gt;exit_signal is expected to be checked for sanity by the caller.</span>
</span><span class="hll"><span class="cm"> */</span>
</span><span class="hll"><span class="kt">pid_t</span> <span class="nf">kernel_clone</span><span class="p">(</span><span class="k">struct</span> <span class="nc">kernel_clone_args</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span><span class="hll"><span class="p">{</span>
</span><span class="hll">	<span class="n">u64</span> <span class="n">clone_flags</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">flags</span><span class="p">;</span>
</span><span class="hll">	<span class="k">struct</span> <span class="nc">completion</span> <span class="n">vfork</span><span class="p">;</span>
</span>	<span class="k">struct</span> <span class="nc">pid</span> <span class="o">*</span><span class="n">pid</span><span class="p">;</span>
	<span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">trace</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="kt">pid_t</span> <span class="n">nr</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * For legacy clone() calls, CLONE_PIDFD uses the parent_tid argument</span>
<span class="cm">	 * to return the pidfd. Hence, CLONE_PIDFD and CLONE_PARENT_SETTID are</span>
<span class="cm">	 * mutually exclusive. With clone3() CLONE_PIDFD has grown a separate</span>
<span class="cm">	 * field in struct clone_args and it still doesn&#39;t make sense to have</span>
<span class="cm">	 * them both point at the same memory location. Performing this check</span>
<span class="cm">	 * here has the advantage that we don&#39;t need to have a separate helper</span>
<span class="cm">	 * to check for legacy clone().</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">((</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">CLONE_PIDFD</span><span class="p">)</span> <span class="o">&amp;&amp;</span>
	    <span class="p">(</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">CLONE_PARENT_SETTID</span><span class="p">)</span> <span class="o">&amp;&amp;</span>
	    <span class="p">(</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">pidfd</span> <span class="o">==</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">parent_tid</span><span class="p">))</span>
		<span class="k">return</span> <span class="o">-</span><span class="n">EINVAL</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Determine whether and which event to report to ptracer.  When</span>
<span class="cm">	 * called from kernel_thread or CLONE_UNTRACED is explicitly</span>
<span class="cm">	 * requested, no event is reported; otherwise, report if the event</span>
<span class="cm">	 * for the type of forking is enabled.</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_UNTRACED</span><span class="p">))</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_VFORK</span><span class="p">)</span>
			<span class="n">trace</span> <span class="o">=</span> <span class="n">PTRACE_EVENT_VFORK</span><span class="p">;</span>
		<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">exit_signal</span> <span class="o">!=</span> <span class="n">SIGCHLD</span><span class="p">)</span>
			<span class="n">trace</span> <span class="o">=</span> <span class="n">PTRACE_EVENT_CLONE</span><span class="p">;</span>
		<span class="k">else</span>
			<span class="n">trace</span> <span class="o">=</span> <span class="n">PTRACE_EVENT_FORK</span><span class="p">;</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="o">!</span><span class="n">ptrace_event_enabled</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">trace</span><span class="p">)))</span>
			<span class="n">trace</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">p</span> <span class="o">=</span> <span class="n">copy_process</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="n">NUMA_NO_NODE</span><span class="p">,</span> <span class="n">args</span><span class="p">);</span>
	<span class="n">add_latent_entropy</span><span class="p">();</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">IS_ERR</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
		<span class="k">return</span> <span class="n">PTR_ERR</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Do this prior waking up the new thread - the thread pointer</span>
<span class="cm">	 * might get invalid after that point, if the thread exits quickly.</span>
<span class="cm">	 */</span>
	<span class="n">trace_sched_process_fork</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>

	<span class="n">pid</span> <span class="o">=</span> <span class="n">get_task_pid</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">PIDTYPE_PID</span><span class="p">);</span>
	<span class="n">nr</span> <span class="o">=</span> <span class="n">pid_vnr</span><span class="p">(</span><span class="n">pid</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_PARENT_SETTID</span><span class="p">)</span>
		<span class="n">put_user</span><span class="p">(</span><span class="n">nr</span><span class="p">,</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">parent_tid</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_VFORK</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">p</span><span class="o">-&gt;</span><span class="n">vfork_done</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">vfork</span><span class="p">;</span>
		<span class="n">init_completion</span><span class="p">(</span><span class="o">&amp;</span><span class="n">vfork</span><span class="p">);</span>
		<span class="n">get_task_struct</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="n">wake_up_new_task</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>

	<span class="cm">/* forking complete and child started to run, tell ptracer */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">trace</span><span class="p">))</span>
		<span class="n">ptrace_event_pid</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">pid</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_VFORK</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">wait_for_vfork_done</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">vfork</span><span class="p">))</span>
			<span class="n">ptrace_event_pid</span><span class="p">(</span><span class="n">PTRACE_EVENT_VFORK_DONE</span><span class="p">,</span> <span class="n">pid</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="n">put_pid</span><span class="p">(</span><span class="n">pid</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">nr</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<p>copy_process –&gt; copy_mm()函数实现</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">copy_mm()实现</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">static</span> <span class="kt">int</span> <span class="n">copy_mm</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">clone_flags</span><span class="p">,</span> <span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span> <span class="o">*</span><span class="n">oldmm</span><span class="p">;</span>

<span class="hll">	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">min_flt</span> <span class="o">=</span> <span class="n">tsk</span><span class="o">-&gt;</span><span class="n">maj_flt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span>	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">nvcsw</span> <span class="o">=</span> <span class="n">tsk</span><span class="o">-&gt;</span><span class="n">nivcsw</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="hll"><span class="cp">#ifdef CONFIG_DETECT_HUNG_TASK</span>
</span><span class="hll">	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">last_switch_count</span> <span class="o">=</span> <span class="n">tsk</span><span class="o">-&gt;</span><span class="n">nvcsw</span> <span class="o">+</span> <span class="n">tsk</span><span class="o">-&gt;</span><span class="n">nivcsw</span><span class="p">;</span>
</span><span class="hll">	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">last_switch_time</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span><span class="hll"><span class="cp">#endif</span>
</span><span class="hll">
</span><span class="hll">	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">mm</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
</span>	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">active_mm</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span> 

	<span class="cm">/*</span>
<span class="cm">	 * Are we cloning a kernel thread?</span>
<span class="cm">	 *</span>
<span class="cm">	 * We need to steal a active VM for that..</span>
<span class="cm">	 */</span>
	<span class="n">oldmm</span> <span class="o">=</span> <span class="n">current</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">;</span> <span class="c1">//init_mm:中-&gt;mm = NULL,所以就直接返回0了,产生内核线程时需要这样处理，第一个内核线程的产生</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">oldmm</span><span class="p">)</span>
		<span class="k">return</span> <span class="mi">0</span><span class="p">;</span> 

	<span class="cm">/* initialize the new vmacache entries */</span>
	<span class="n">vmacache_flush</span><span class="p">(</span><span class="n">tsk</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">clone_flags</span> <span class="o">&amp;</span> <span class="n">CLONE_VM</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">mmget</span><span class="p">(</span><span class="n">oldmm</span><span class="p">);</span>
		<span class="n">mm</span> <span class="o">=</span> <span class="n">oldmm</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">mm</span> <span class="o">=</span> <span class="n">dup_mm</span><span class="p">(</span><span class="n">tsk</span><span class="p">,</span> <span class="n">current</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">);</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mm</span><span class="p">)</span>
			<span class="k">return</span> <span class="o">-</span><span class="n">ENOMEM</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">mm</span> <span class="o">=</span> <span class="n">mm</span><span class="p">;</span>
	<span class="n">tsk</span><span class="o">-&gt;</span><span class="n">active_mm</span> <span class="o">=</span> <span class="n">mm</span><span class="p">;</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<p>我们假设为通过函数产生的第一个进程，则 current_task == init_task,定义如下：</p>
<div class="literal-block-wrapper docutils container" id="init-task">
<div class="code-block-caption"><span class="caption-text">init_task.mm初始化</span><a class="headerlink" href="#init-task" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42</pre></div></td><td class="code"><div class="highlight"><pre><span></span>/*
 * Set up the first task table, touch at your own risk!. Base=0,
 * limit=0x1fffff (=2MB)
 */
<span class="hll">struct task_struct init_task
</span>#ifdef CONFIG_ARCH_TASK_STRUCT_ON_STACK
<span class="hll">	__init_task_data
</span><span class="hll">#endif
</span><span class="hll">	__aligned(L1_CACHE_BYTES)
</span><span class="hll">= {
</span><span class="hll">......
</span><span class="hll">	.mm		= NULL,
</span>	.active_mm	= &amp;init_mm,
......
};



*
 * For dynamically allocated mm_structs, there is a dynamically sized cpumask
 * at the end of the structure, the size of which depends on the maximum CPU
 * number the system can see. That way we allocate only as much memory for
 * mm_cpumask() as needed for the hundreds, or thousands of processes that
 * a system typically runs.
 *
 * Since there is only one init_mm in the entire system, keep it simple
 * and size this cpu_bitmask to NR_CPUS.
 */
struct mm_struct init_mm = {
	.mm_rb		= RB_ROOT,
	.pgd		= swapper_pg_dir,
	.mm_users	= ATOMIC_INIT(2),
	.mm_count	= ATOMIC_INIT(1),
	.write_protect_seq = SEQCNT_ZERO(init_mm.write_protect_seq),
	MMAP_LOCK_INITIALIZER(init_mm)
	.page_table_lock =  __SPIN_LOCK_UNLOCKED(init_mm.page_table_lock),
	.arg_lock	=  __SPIN_LOCK_UNLOCKED(init_mm.arg_lock),
	.mmlist		= LIST_HEAD_INIT(init_mm.mmlist),
	.user_ns	= &amp;init_user_ns,
	.cpu_bitmap	= CPU_BITS_NONE,
	INIT_MM_CONTEXT(init_mm)
};
</pre></div>
</td></tr></table></div>
</div>
<p>因为内核线程不需要切换CR3寄存器，我们现在看第一个应用进程的产生，内核进程运行 run_init_process()</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">mm_alloc原理</span><a class="headerlink" href="#id7" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/*</span>
<span class="cm"> * Allocate and initialize an mm_struct.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm_alloc</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="hll"><span class="p">{</span>
</span>	<span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">;</span>
<span class="hll">
</span><span class="hll">	<span class="n">mm</span> <span class="o">=</span> <span class="n">allocate_mm</span><span class="p">();</span>
</span><span class="hll">	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mm</span><span class="p">)</span>
</span><span class="hll">		<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
</span><span class="hll">
</span><span class="hll">	<span class="n">memset</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">mm</span><span class="p">));</span>
</span>	<span class="k">return</span> <span class="nf">mm_init</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">current_user_ns</span><span class="p">());</span>
<span class="p">}</span>


<span class="k">static</span> <span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm_init</span><span class="p">(</span><span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span> <span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">p</span><span class="p">,</span>
	<span class="k">struct</span> <span class="nc">user_namespace</span> <span class="o">*</span><span class="n">user_ns</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">mmap</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">mm_rb</span> <span class="o">=</span> <span class="n">RB_ROOT</span><span class="p">;</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">vmacache_seqnum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">atomic_set</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">mm_users</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
	<span class="n">atomic_set</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">mm_count</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
	<span class="n">seqcount_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">write_protect_seq</span><span class="p">);</span>
	<span class="n">mmap_init_lock</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">INIT_LIST_HEAD</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">mmlist</span><span class="p">);</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">core_state</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
	<span class="n">mm_pgtables_bytes_init</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">map_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">locked_vm</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">atomic64_set</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">pinned_vm</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">rss_stat</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">rss_stat</span><span class="p">));</span>
	<span class="n">spin_lock_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">page_table_lock</span><span class="p">);</span>
	<span class="n">spin_lock_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">arg_lock</span><span class="p">);</span>
	<span class="n">mm_init_cpumask</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">mm_init_aio</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">mm_init_owner</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
	<span class="n">mm_init_pasid</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">RCU_INIT_POINTER</span><span class="p">(</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">exe_file</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
	<span class="n">mmu_notifier_subscriptions_init</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">init_tlb_flush_pending</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
<span class="cp">#if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">pmd_huge_pte</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
<span class="cp">#endif</span>
	<span class="n">mm_init_uprobes_state</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="n">hugetlb_count_init</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">current</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">mm</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">=</span> <span class="n">current</span><span class="o">-&gt;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">MMF_INIT_MASK</span><span class="p">;</span>
		<span class="n">mm</span><span class="o">-&gt;</span><span class="n">def_flags</span> <span class="o">=</span> <span class="n">current</span><span class="o">-&gt;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">def_flags</span> <span class="o">&amp;</span> <span class="n">VM_INIT_DEF_MASK</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">mm</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">=</span> <span class="n">default_dump_filter</span><span class="p">;</span>
		<span class="n">mm</span><span class="o">-&gt;</span><span class="n">def_flags</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">mm_alloc_pgd</span><span class="p">(</span><span class="n">mm</span><span class="p">))</span>  <span class="c1">// 关注这个点</span>
		<span class="k">goto</span> <span class="n">fail_nopgd</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">init_new_context</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">mm</span><span class="p">))</span>
		<span class="k">goto</span> <span class="n">fail_nocontext</span><span class="p">;</span>

	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">user_ns</span> <span class="o">=</span> <span class="n">get_user_ns</span><span class="p">(</span><span class="n">user_ns</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">mm</span><span class="p">;</span>

<span class="nl">fail_nocontext</span><span class="p">:</span>
	<span class="n">mm_free_pgd</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
<span class="nl">fail_nopgd</span><span class="p">:</span>
	<span class="n">free_mm</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
<span class="p">}</span>


<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="n">mm_alloc_pgd</span><span class="p">(</span><span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">pgd</span> <span class="o">=</span> <span class="n">pgd_alloc</span><span class="p">(</span><span class="n">mm</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="o">!</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">pgd</span><span class="p">))</span>
		<span class="k">return</span> <span class="o">-</span><span class="n">ENOMEM</span><span class="p">;</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>


<span class="n">pgd_t</span> <span class="o">*</span><span class="n">pgd_alloc</span><span class="p">(</span><span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">pgd_t</span> <span class="o">*</span><span class="n">pgd</span><span class="p">;</span>
	<span class="n">pmd_t</span> <span class="o">*</span><span class="n">u_pmds</span><span class="p">[</span><span class="n">MAX_PREALLOCATED_USER_PMDS</span><span class="p">];</span>
	<span class="n">pmd_t</span> <span class="o">*</span><span class="n">pmds</span><span class="p">[</span><span class="n">MAX_PREALLOCATED_PMDS</span><span class="p">];</span>

	<span class="n">pgd</span> <span class="o">=</span> <span class="n">_pgd_alloc</span><span class="p">();</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">pgd</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">)</span>
		<span class="k">goto</span> <span class="n">out</span><span class="p">;</span>

	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">pgd</span> <span class="o">=</span> <span class="n">pgd</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">preallocate_pmds</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pmds</span><span class="p">,</span> <span class="n">PREALLOCATED_PMDS</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
		<span class="k">goto</span> <span class="n">out_free_pgd</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">preallocate_pmds</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">u_pmds</span><span class="p">,</span> <span class="n">PREALLOCATED_USER_PMDS</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
		<span class="k">goto</span> <span class="n">out_free_pmds</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">paravirt_pgd_alloc</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
		<span class="k">goto</span> <span class="n">out_free_user_pmds</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Make sure that pre-populating the pmds is atomic with</span>
<span class="cm">	 * respect to anything walking the pgd_list, so that they</span>
<span class="cm">	 * never see a partially populated pgd.</span>
<span class="cm">	 */</span>
	<span class="n">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pgd_lock</span><span class="p">);</span>

	<span class="n">pgd_ctor</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pgd</span><span class="p">);</span> <span class="c1">//我们注意这个函数</span>
	<span class="n">pgd_prepopulate_pmd</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pgd</span><span class="p">,</span> <span class="n">pmds</span><span class="p">);</span>
	<span class="n">pgd_prepopulate_user_pmd</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pgd</span><span class="p">,</span> <span class="n">u_pmds</span><span class="p">);</span>

	<span class="n">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pgd_lock</span><span class="p">);</span>

	<span class="k">return</span> <span class="n">pgd</span><span class="p">;</span>

<span class="nl">out_free_user_pmds</span><span class="p">:</span>
	<span class="n">free_pmds</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">u_pmds</span><span class="p">,</span> <span class="n">PREALLOCATED_USER_PMDS</span><span class="p">);</span>
<span class="nl">out_free_pmds</span><span class="p">:</span>
	<span class="n">free_pmds</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pmds</span><span class="p">,</span> <span class="n">PREALLOCATED_PMDS</span><span class="p">);</span>
<span class="nl">out_free_pgd</span><span class="p">:</span>
	<span class="n">_pgd_free</span><span class="p">(</span><span class="n">pgd</span><span class="p">);</span>
<span class="nl">out</span><span class="p">:</span>
	<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
<span class="p">}</span>


<span class="k">static</span> <span class="kt">void</span> <span class="n">pgd_ctor</span><span class="p">(</span><span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span> <span class="n">pgd_t</span> <span class="o">*</span><span class="n">pgd</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* If the pgd points to a shared pagetable level (either the</span>
<span class="cm">	   ptes in non-PAE, or shared PMD in PAE), then just copy the</span>
<span class="cm">	   references from swapper_pg_dir. */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">CONFIG_PGTABLE_LEVELS</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">||</span>
	    <span class="p">(</span><span class="n">CONFIG_PGTABLE_LEVELS</span> <span class="o">==</span> <span class="mi">3</span> <span class="o">&amp;&amp;</span> <span class="n">SHARED_KERNEL_PMD</span><span class="p">)</span> <span class="o">||</span>
	    <span class="n">CONFIG_PGTABLE_LEVELS</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">clone_pgd_range</span><span class="p">(</span><span class="n">pgd</span> <span class="o">+</span> <span class="n">KERNEL_PGD_BOUNDARY</span><span class="p">,</span> <span class="c1">//内核空家复制，所以每个进程都有自己的内核空间页表。</span>
				<span class="n">swapper_pg_dir</span> <span class="o">+</span> <span class="n">KERNEL_PGD_BOUNDARY</span><span class="p">,</span>
				<span class="n">KERNEL_PGD_PTRS</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="cm">/* list required to sync kernel mapping updates */</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">SHARED_KERNEL_PMD</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">pgd_set_mm</span><span class="p">(</span><span class="n">pgd</span><span class="p">,</span> <span class="n">mm</span><span class="p">);</span>
		<span class="n">pgd_list_add</span><span class="p">(</span><span class="n">pgd</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>










</pre></div>
</td></tr></table></div>
</div>
<p>现在我们看进程切换时，内存的处理方法：</p>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text">进程切换中：switch_mm</span><a class="headerlink" href="#id8" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/*</span>
<span class="cm"> * context_switch - switch to the new MM and the new thread&#39;s register state.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">__always_inline</span> <span class="k">struct</span> <span class="nc">rq</span> <span class="o">*</span>
<span class="hll"><span class="n">context_switch</span><span class="p">(</span><span class="k">struct</span> <span class="nc">rq</span> <span class="o">*</span><span class="n">rq</span><span class="p">,</span> <span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
</span>	       <span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">,</span> <span class="k">struct</span> <span class="nc">rq_flags</span> <span class="o">*</span><span class="n">rf</span><span class="p">)</span>
<span class="hll"><span class="p">{</span>
</span><span class="hll">	<span class="n">prepare_task_switch</span><span class="p">(</span><span class="n">rq</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span>
</span><span class="hll">
</span><span class="hll">	<span class="cm">/*</span>
</span><span class="hll"><span class="cm">	 * For paravirt, this is coupled with an exit in switch_to to</span>
</span><span class="hll"><span class="cm">	 * combine the page table reload and the switch backend into</span>
</span><span class="cm">	 * one hypercall.</span>
<span class="cm">	 */</span>
	<span class="n">arch_start_context_switch</span><span class="p">(</span><span class="n">prev</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * kernel -&gt; kernel   lazy + transfer active</span>
<span class="cm">	 *   user -&gt; kernel   lazy + mmgrab() active</span>
<span class="cm">	 *</span>
<span class="cm">	 * kernel -&gt;   user   switch + mmdrop() active</span>
<span class="cm">	 *   user -&gt;   user   switch</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">next</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">)</span> <span class="p">{</span>                                <span class="c1">// to kernel,切换到内核线程，不进行CR3切换</span>
		<span class="n">enter_lazy_tlb</span><span class="p">(</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span>

		<span class="n">next</span><span class="o">-&gt;</span><span class="n">active_mm</span> <span class="o">=</span> <span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">;</span>    <span class="c1">//第一次从init_task 切换到其他内核线程时，next-&gt;active_mm = init_mm</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">)</span>                           <span class="c1">// from user</span>
			<span class="n">mmgrab</span><span class="p">(</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">);</span>
		<span class="k">else</span>
			<span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span> <span class="c1">//如果上一个进程也是内核进程</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>                                        <span class="c1">// to user</span>
		<span class="n">membarrier_switch_mm</span><span class="p">(</span><span class="n">rq</span><span class="p">,</span> <span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">,</span> <span class="n">next</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">);</span>
		<span class="cm">/*</span>
<span class="cm">		 * sys_membarrier() requires an smp_mb() between setting</span>
<span class="cm">		 * rq-&gt;curr / membarrier_switch_mm() and returning to userspace.</span>
<span class="cm">		 *</span>
<span class="cm">		 * The below provides this either through switch_mm(), or in</span>
<span class="cm">		 * case &#39;prev-&gt;active_mm == next-&gt;mm&#39; through</span>
<span class="cm">		 * finish_task_switch()&#39;s mmdrop().</span>
<span class="cm">		 */</span>
		<span class="n">switch_mm_irqs_off</span><span class="p">(</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">,</span> <span class="n">next</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span><span class="c1">//这个函数复制内核部分，所有进程内核进程页面映射相同，所以切换与不切换不影响当前内核上下文的执行。</span>

		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">prev</span><span class="o">-&gt;</span><span class="n">mm</span><span class="p">)</span> <span class="p">{</span>                        <span class="c1">// from kernel，从内核进程向外切换</span>
			<span class="cm">/* will mmdrop() in finish_task_switch(). */</span>
			<span class="n">rq</span><span class="o">-&gt;</span><span class="n">prev_mm</span> <span class="o">=</span> <span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span><span class="p">;</span>
			<span class="n">prev</span><span class="o">-&gt;</span><span class="n">active_mm</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="n">rq</span><span class="o">-&gt;</span><span class="n">clock_update_flags</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="p">(</span><span class="n">RQCF_ACT_SKIP</span><span class="o">|</span><span class="n">RQCF_REQ_SKIP</span><span class="p">);</span>

	<span class="n">prepare_lock_switch</span><span class="p">(</span><span class="n">rq</span><span class="p">,</span> <span class="n">next</span><span class="p">,</span> <span class="n">rf</span><span class="p">);</span>

	<span class="cm">/* Here we just switch the register state and the stack. */</span>
	<span class="n">switch_to</span><span class="p">(</span><span class="n">prev</span><span class="p">,</span> <span class="n">next</span><span class="p">,</span> <span class="n">prev</span><span class="p">);</span>
	<span class="n">barrier</span><span class="p">();</span>

	<span class="k">return</span> <span class="nf">finish_task_switch</span><span class="p">(</span><span class="n">prev</span><span class="p">);</span>
<span class="p">}</span>


<span class="kt">void</span> <span class="n">switch_mm_irqs_off</span><span class="p">(</span><span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span> <span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">,</span>
			<span class="k">struct</span> <span class="nc">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="nc">mm_struct</span> <span class="o">*</span><span class="n">real_prev</span> <span class="o">=</span> <span class="n">this_cpu_read</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">loaded_mm</span><span class="p">);</span>
	<span class="n">u16</span> <span class="n">prev_asid</span> <span class="o">=</span> <span class="n">this_cpu_read</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">loaded_mm_asid</span><span class="p">);</span>
	<span class="kt">bool</span> <span class="n">was_lazy</span> <span class="o">=</span> <span class="n">this_cpu_read</span><span class="p">(</span><span class="n">cpu_tlbstate_shared</span><span class="p">.</span><span class="n">is_lazy</span><span class="p">);</span>
	<span class="kt">unsigned</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="n">u64</span> <span class="n">next_tlb_gen</span><span class="p">;</span>
	<span class="kt">bool</span> <span class="n">need_flush</span><span class="p">;</span>
	<span class="n">u16</span> <span class="n">new_asid</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * NB: The scheduler will call us with prev == next when switching</span>
<span class="cm">	 * from lazy TLB mode to normal mode if active_mm isn&#39;t changing.</span>
<span class="cm">	 * When this happens, we don&#39;t assume that CR3 (and hence</span>
<span class="cm">	 * cpu_tlbstate.loaded_mm) matches next.</span>
<span class="cm">	 *</span>
<span class="cm">	 * NB: leave_mm() calls us with prev == NULL and tsk == NULL.</span>
<span class="cm">	 */</span>

	<span class="cm">/* We don&#39;t want flush_tlb_func() to run concurrently with us. */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">IS_ENABLED</span><span class="p">(</span><span class="n">CONFIG_PROVE_LOCKING</span><span class="p">))</span>
		<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="o">!</span><span class="n">irqs_disabled</span><span class="p">());</span>

	<span class="cm">/*</span>
<span class="cm">	 * Verify that CR3 is what we think it is.  This will catch</span>
<span class="cm">	 * hypothetical buggy code that directly switches to swapper_pg_dir</span>
<span class="cm">	 * without going through leave_mm() / switch_mm_irqs_off() or that</span>
<span class="cm">	 * does something like write_cr3(read_cr3_pa()).</span>
<span class="cm">	 *</span>
<span class="cm">	 * Only do this check if CONFIG_DEBUG_VM=y because __read_cr3()</span>
<span class="cm">	 * isn&#39;t free.</span>
<span class="cm">	 */</span>
<span class="cp">#ifdef CONFIG_DEBUG_VM</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">__read_cr3</span><span class="p">()</span> <span class="o">!=</span> <span class="n">build_cr3</span><span class="p">(</span><span class="n">real_prev</span><span class="o">-&gt;</span><span class="n">pgd</span><span class="p">,</span> <span class="n">prev_asid</span><span class="p">)))</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * If we were to BUG here, we&#39;d be very likely to kill</span>
<span class="cm">		 * the system so hard that we don&#39;t see the call trace.</span>
<span class="cm">		 * Try to recover instead by ignoring the error and doing</span>
<span class="cm">		 * a global flush to minimize the chance of corruption.</span>
<span class="cm">		 *</span>
<span class="cm">		 * (This is far from being a fully correct recovery.</span>
<span class="cm">		 *  Architecturally, the CPU could prefetch something</span>
<span class="cm">		 *  back into an incorrect ASID slot and leave it there</span>
<span class="cm">		 *  to cause trouble down the road.  It&#39;s better than</span>
<span class="cm">		 *  nothing, though.)</span>
<span class="cm">		 */</span>
		<span class="n">__flush_tlb_all</span><span class="p">();</span>
	<span class="p">}</span>
<span class="cp">#endif</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">was_lazy</span><span class="p">)</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate_shared</span><span class="p">.</span><span class="n">is_lazy</span><span class="p">,</span> <span class="nb">false</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * The membarrier system call requires a full memory barrier and</span>
<span class="cm">	 * core serialization before returning to user-space, after</span>
<span class="cm">	 * storing to rq-&gt;curr, when changing mm.  This is because</span>
<span class="cm">	 * membarrier() sends IPIs to all CPUs that are in the target mm</span>
<span class="cm">	 * to make them issue memory barriers.  However, if another CPU</span>
<span class="cm">	 * switches to/from the target mm concurrently with</span>
<span class="cm">	 * membarrier(), it can cause that CPU not to receive an IPI</span>
<span class="cm">	 * when it really should issue a memory barrier.  Writing to CR3</span>
<span class="cm">	 * provides that full memory barrier and core serializing</span>
<span class="cm">	 * instruction.</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">real_prev</span> <span class="o">==</span> <span class="n">next</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">VM_WARN_ON</span><span class="p">(</span><span class="n">this_cpu_read</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">ctxs</span><span class="p">[</span><span class="n">prev_asid</span><span class="p">].</span><span class="n">ctx_id</span><span class="p">)</span> <span class="o">!=</span>
			   <span class="n">next</span><span class="o">-&gt;</span><span class="n">context</span><span class="p">.</span><span class="n">ctx_id</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * Even in lazy TLB mode, the CPU should stay set in the</span>
<span class="cm">		 * mm_cpumask. The TLB shootdown code can figure out from</span>
<span class="cm">		 * cpu_tlbstate_shared.is_lazy whether or not to send an IPI.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">real_prev</span> <span class="o">!=</span> <span class="o">&amp;</span><span class="n">init_mm</span> <span class="o">&amp;&amp;</span>
				 <span class="o">!</span><span class="n">cpumask_test_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mm_cpumask</span><span class="p">(</span><span class="n">next</span><span class="p">))))</span>
			<span class="n">cpumask_set_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mm_cpumask</span><span class="p">(</span><span class="n">next</span><span class="p">));</span>

		<span class="cm">/*</span>
<span class="cm">		 * If the CPU is not in lazy TLB mode, we are just switching</span>
<span class="cm">		 * from one thread in a process to another thread in the same</span>
<span class="cm">		 * process. No TLB flush required.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">was_lazy</span><span class="p">)</span>
			<span class="k">return</span><span class="p">;</span>

		<span class="cm">/*</span>
<span class="cm">		 * Read the tlb_gen to check whether a flush is needed.</span>
<span class="cm">		 * If the TLB is up to date, just use it.</span>
<span class="cm">		 * The barrier synchronizes with the tlb_gen increment in</span>
<span class="cm">		 * the TLB shootdown code.</span>
<span class="cm">		 */</span>
		<span class="n">smp_mb</span><span class="p">();</span>
		<span class="n">next_tlb_gen</span> <span class="o">=</span> <span class="n">atomic64_read</span><span class="p">(</span><span class="o">&amp;</span><span class="n">next</span><span class="o">-&gt;</span><span class="n">context</span><span class="p">.</span><span class="n">tlb_gen</span><span class="p">);</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">this_cpu_read</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">ctxs</span><span class="p">[</span><span class="n">prev_asid</span><span class="p">].</span><span class="n">tlb_gen</span><span class="p">)</span> <span class="o">==</span>
				<span class="n">next_tlb_gen</span><span class="p">)</span>
			<span class="k">return</span><span class="p">;</span>

		<span class="cm">/*</span>
<span class="cm">		 * TLB contents went out of date while we were in lazy</span>
<span class="cm">		 * mode. Fall through to the TLB switching code below.</span>
<span class="cm">		 */</span>
		<span class="n">new_asid</span> <span class="o">=</span> <span class="n">prev_asid</span><span class="p">;</span>
		<span class="n">need_flush</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * Avoid user/user BTB poisoning by flushing the branch</span>
<span class="cm">		 * predictor when switching between processes. This stops</span>
<span class="cm">		 * one process from doing Spectre-v2 attacks on another.</span>
<span class="cm">		 */</span>
		<span class="n">cond_ibpb</span><span class="p">(</span><span class="n">tsk</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * Stop remote flushes for the previous mm.</span>
<span class="cm">		 * Skip kernel threads; we never send init_mm TLB flushing IPIs,</span>
<span class="cm">		 * but the bitmap manipulation can cause cache line contention.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">real_prev</span> <span class="o">!=</span> <span class="o">&amp;</span><span class="n">init_mm</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">VM_WARN_ON_ONCE</span><span class="p">(</span><span class="o">!</span><span class="n">cpumask_test_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span>
						<span class="n">mm_cpumask</span><span class="p">(</span><span class="n">real_prev</span><span class="p">)));</span>
			<span class="n">cpumask_clear_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mm_cpumask</span><span class="p">(</span><span class="n">real_prev</span><span class="p">));</span>
		<span class="p">}</span>

		<span class="cm">/*</span>
<span class="cm">		 * Start remote flushes and then read tlb_gen.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">next</span> <span class="o">!=</span> <span class="o">&amp;</span><span class="n">init_mm</span><span class="p">)</span>
			<span class="n">cpumask_set_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mm_cpumask</span><span class="p">(</span><span class="n">next</span><span class="p">));</span>
		<span class="n">next_tlb_gen</span> <span class="o">=</span> <span class="n">atomic64_read</span><span class="p">(</span><span class="o">&amp;</span><span class="n">next</span><span class="o">-&gt;</span><span class="n">context</span><span class="p">.</span><span class="n">tlb_gen</span><span class="p">);</span>

		<span class="n">choose_new_asid</span><span class="p">(</span><span class="n">next</span><span class="p">,</span> <span class="n">next_tlb_gen</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">new_asid</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">need_flush</span><span class="p">);</span>

		<span class="cm">/* Let nmi_uaccess_okay() know that we&#39;re changing CR3. */</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">loaded_mm</span><span class="p">,</span> <span class="n">LOADED_MM_SWITCHING</span><span class="p">);</span>
		<span class="n">barrier</span><span class="p">();</span>
	<span class="p">}</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">need_flush</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">ctxs</span><span class="p">[</span><span class="n">new_asid</span><span class="p">].</span><span class="n">ctx_id</span><span class="p">,</span> <span class="n">next</span><span class="o">-&gt;</span><span class="n">context</span><span class="p">.</span><span class="n">ctx_id</span><span class="p">);</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">ctxs</span><span class="p">[</span><span class="n">new_asid</span><span class="p">].</span><span class="n">tlb_gen</span><span class="p">,</span> <span class="n">next_tlb_gen</span><span class="p">);</span>
		<span class="n">load_new_mm_cr3</span><span class="p">(</span><span class="n">next</span><span class="o">-&gt;</span><span class="n">pgd</span><span class="p">,</span> <span class="n">new_asid</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span> <span class="c1">//CR3寄存器切换</span>

		<span class="n">trace_tlb_flush</span><span class="p">(</span><span class="n">TLB_FLUSH_ON_TASK_SWITCH</span><span class="p">,</span> <span class="n">TLB_FLUSH_ALL</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/* The new ASID is already up to date. */</span>
		<span class="n">load_new_mm_cr3</span><span class="p">(</span><span class="n">next</span><span class="o">-&gt;</span><span class="n">pgd</span><span class="p">,</span> <span class="n">new_asid</span><span class="p">,</span> <span class="nb">false</span><span class="p">);</span>  <span class="c1">//CR3寄存器切换</span>

		<span class="n">trace_tlb_flush</span><span class="p">(</span><span class="n">TLB_FLUSH_ON_TASK_SWITCH</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="cm">/* Make sure we write CR3 before loaded_mm. */</span>
	<span class="n">barrier</span><span class="p">();</span>

	<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">loaded_mm</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span>
	<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">cpu_tlbstate</span><span class="p">.</span><span class="n">loaded_mm_asid</span><span class="p">,</span> <span class="n">new_asid</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">next</span> <span class="o">!=</span> <span class="n">real_prev</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">cr4_update_pce_mm</span><span class="p">(</span><span class="n">next</span><span class="p">);</span>
		<span class="n">switch_ldt</span><span class="p">(</span><span class="n">real_prev</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>




<span class="k">static</span> <span class="kt">void</span> <span class="n">load_new_mm_cr3</span><span class="p">(</span><span class="n">pgd_t</span> <span class="o">*</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">u16</span> <span class="n">new_asid</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">need_flush</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">new_mm_cr3</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">need_flush</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">invalidate_user_asid</span><span class="p">(</span><span class="n">new_asid</span><span class="p">);</span>
		<span class="n">new_mm_cr3</span> <span class="o">=</span> <span class="n">build_cr3</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">new_asid</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">new_mm_cr3</span> <span class="o">=</span> <span class="n">build_cr3_noflush</span><span class="p">(</span><span class="n">pgdir</span><span class="p">,</span> <span class="n">new_asid</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="cm">/*</span>
<span class="cm">	 * Caution: many callers of this function expect</span>
<span class="cm">	 * that load_cr3() is serializing and orders TLB</span>
<span class="cm">	 * fills with respect to the mm_cpumask writes.</span>
<span class="cm">	 */</span>
	<span class="n">write_cr3</span><span class="p">(</span><span class="n">new_mm_cr3</span><span class="p">);</span><span class="c1">//完成CR3寄存器切换</span>
<span class="p">}</span>










</pre></div>
</td></tr></table></div>
</div>
<dl class="simple">
<dt>我们以X86平台为例，做个总结：</dt><dd><ol class="arabic simple">
<li><p>进程切换时，如果目标进程为内核进程，不需要切换CR3；若为应用进程，则需要切换CR3；</p></li>
<li><p>第一个进程，mm == NULL,active_mm == init_mm；</p></li>
<li><p>第一个应用进程，通过run_init_process –&gt; kernel_execve –&gt; alloc_bprm() –&gt; mmalloc():实现task_struct -&gt; mm_struct <a href="#id9"><span class="problematic" id="id10">*</span></a>mm的分配，并拷贝swapper_pg_dir到mm-&gt;pgd,这样内核空间也表初始化完成；</p></li>
<li><p>应用进程：父进程运行fork() –&gt; copy_mm(),为子进程分配struct task_struct 结构，并将task-&gt;mm指向父进程的task-&gt;mm；子进程运行execxxx() –&gt; kernel_execve() –&gt; alloc_bprm() –&gt;mmalloc()真正拥有自己的task-&gt;mm,并拷贝swapper_pg_dir到mm-&gt;pgd,这样内核空间也表初始化完成.</p></li>
</ol>
</dd>
</dl>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Rachel.Sun.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>