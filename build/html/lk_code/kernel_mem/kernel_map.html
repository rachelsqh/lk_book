<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>内核内存布局 &mdash; Rachel&#39;s E-book 1.0 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Rachel's E-book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../os_base/index.html">linux 操作系统架构分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lk_devel/index.html">linux 内核开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">linux 内核代码分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../os_sec/index.html">linux 操作系统安全</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../my_os/index.html">从零开始写一个系统（KVM）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../csxj/index.html">处世悬镜</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Rachel's E-book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>内核内存布局</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/lk_code/kernel_mem/kernel_map.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="id1">
<h1>内核内存布局<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>systemap:这个里面是符号与地址对应关系。</p>
</div>
<div class="section" id="vmlinux">
<h1>vmlinux内核内存布局<a class="headerlink" href="#vmlinux" title="Permalink to this headline">¶</a></h1>
<p>img</p>
<p>其中的赋值并不占用空间，这些参数在其他地方存储，此处只是对其中的值进行赋值。
我们再重新看链接脚本的作用：</p>
</div>
<div class="section" id="id2">
<h1>内核的加载<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h1>
<p>内核加载完成后参考如上，也就是说跳转到startup64时就已经完成内核的整个定位了。我们看说明：
startup_64:</p>
<blockquote>
<div><dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>At this point the CPU runs in 64bit mode CS.L = 1 CS.D = 0,</p></li>
<li><p>and someone has loaded an identity mapped page table</p></li>
<li><p>for us.  These identity mapped page tables map all of the</p></li>
<li><p>kernel pages and possibly all of memory.</p></li>
<li></li>
<li><p>%rsi holds a physical pointer to real_mode_data.</p></li>
<li></li>
<li><p>We come here either directly from a 64bit bootloader, or from</p></li>
<li><p>arch/x86/boot/compressed/head_64.S.</p></li>
<li></li>
<li><p>We only come here initially at boot nothing else comes here.</p></li>
<li></li>
<li><p>Since we may be loaded at an address different from what we were</p></li>
<li><p>compiled to run at we first fixup the physical addresses in our page</p></li>
<li><p>tables and then reload them.</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
</dl>
<p>/* Set up the stack for verify_cpu(), similar to initial_stack below <a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</div></blockquote>
<p>此时 CPU 运行在 64 位模式 CS.L = 1 CS.D = 0，并且有人为我们加载了身份映射页表。 这些身份映射页表映射所有内核页面，可能还映射所有内存。 %rsi 拥有一个指向 real_mode_data 的物理指针。我们可以直接从 64 位引导加载程序或从 arch/x86/boot/compressed/head_64.S 来。 我们最初只是在启动时来到这里，没有其他东西来到这里。 由于我们可能被加载到与我们编译运行的地址不同的地址，我们首先修复页表中的物理地址，然后重新加载它们。</p>
<p>从这个位置往下看的时候记得所有的映射已经做好了</p>
<p>leaq    (__end_init_task - FRAME_SIZE)(%rip), %rsp //栈：用的init_task的__end_init_task,空出了FRAME_SIZE的空间，这一块是在数据段中已经存在</p>
<blockquote>
<div><p>leaq    _text(%rip), %rdi   //相对寻址，rdi 指向_text地址
pushq   %rsi
call    startup_64_setup_env //加载GDT和IDT</p>
</div></blockquote>
<p>//startup_64_setup_env  begian
在内核切换到虚拟地址之前需要设置引导 CPU 状态。</p>
<p>/* 8 byte segment descriptor <a href="#id7"><span class="problematic" id="id8">*</span></a>/
struct desc_struct {</p>
<blockquote>
<div><p>u16     limit0;
u16     base0;
u16     base1: 8, type: 4, s: 1, dpl: 2, p: 1;
u16     limit1: 4, avl: 1, l: 1, d: 1, g: 1, base2: 8;</p>
</div></blockquote>
<p>} __attribute__((packed));</p>
<dl>
<dt>#define GDT_ENTRY_INIT(flags, base, limit)                      </dt><dd><dl class="simple">
<dt>{                                                       </dt><dd><p>.limit0         = (u16) (limit),                .limit1         = ((limit) &gt;&gt; 16) &amp; 0x0F,       .base0          = (u16) (base),                 .base1          = ((base) &gt;&gt; 16) &amp; 0xFF,        .base2          = ((base) &gt;&gt; 24) &amp; 0xFF,        .type           = (flags &amp; 0x0f),               .s              = (flags &gt;&gt; 4) &amp; 0x01,          .dpl            = (flags &gt;&gt; 5) &amp; 0x03,          .p              = (flags &gt;&gt; 7) &amp; 0x01,          .avl            = (flags &gt;&gt; 12) &amp; 0x01,         .l              = (flags &gt;&gt; 13) &amp; 0x01,         .d              = (flags &gt;&gt; 14) &amp; 0x01,         .g              = (flags &gt;&gt; 15) &amp; 0x01,         </p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>struct desc_ptr {</dt><dd><p>unsigned short size;
unsigned long address;</p>
</dd>
</dl>
<p>} __attribute__((packed)) ;</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>GDT used on the boot CPU before switching to virtual addresses.</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
<dt>static struct desc_struct startup_gdt[GDT_ENTRIES] = {</dt><dd><p>[GDT_ENTRY_KERNEL32_CS]         = GDT_ENTRY_INIT(0xc09b, 0, 0xfffff),
[GDT_ENTRY_KERNEL_CS]           = GDT_ENTRY_INIT(0xa09b, 0, 0xfffff),
[GDT_ENTRY_KERNEL_DS]           = GDT_ENTRY_INIT(0xc093, 0, 0xfffff),</p>
</dd>
</dl>
<p>};</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Address needs to be set at runtime because it references the startup_gdt</p></li>
<li><p>while the kernel still uses a direct mapping.</p></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
<dt>static struct desc_ptr startup_gdt_descr = {</dt><dd><p>.size = sizeof(startup_gdt),
.address = 0,</p>
</dd>
</dl>
<p>};</p>
<p>void __head startup_64_setup_env(unsigned long physbase) //参数rdi:_text地址：_text = 0xffffffff81000000，相对寻址，加载GDT但没有初始化CS
{</p>
<blockquote>
<div><p>/* Load GDT <a href="#id13"><span class="problematic" id="id14">*</span></a>/
startup_gdt_descr.address = (unsigned long)fixup_pointer(startup_gdt, physbase); //return ptr - (void <a href="#id15"><span class="problematic" id="id16">*</span></a>)_text + (void <a href="#id17"><span class="problematic" id="id18">*</span></a>)physaddr;离_text的距离
native_load_gdt(&amp;startup_gdt_descr);//  asm volatile(“lgdt %0”::”m” (<a href="#id19"><span class="problematic" id="id20">*</span></a>dtr));</p>
<p>/* New GDT is live - reload data segment registers ：重新加载GDT <a href="#id21"><span class="problematic" id="id22">*</span></a>/
asm volatile(“movl %%eax, %%dsn”</p>
<blockquote>
<div><p>“movl %%eax, %%ssn”
“movl %%eax, %%esn” : : “a”(__KERNEL_DS) : “memory”); //ds = ss = es = __KERNEL_DS</p>
</div></blockquote>
<p>startup_64_load_idt(physbase);//加载IDT 这仍然在直接映射中运行</p>
</div></blockquote>
<dl>
<dt>#if 0</dt><dd><p>/* This runs while still in the direct mapping:这仍然在直接映射中运行 <a href="#id23"><span class="problematic" id="id24">*</span></a>/</p>
</dd>
<dt>/*</dt><dd><ul class="simple">
<li><p>Data structures and code used for IDT setup in head_64.S. The bringup-IDT is</p></li>
<li><p>used until the idt_table takes over. On the boot CPU this happens in</p></li>
<li><p>x86_64_start_kernel(), on secondary CPUs in start_secondary(). In both cases</p></li>
<li><p>this happens in the functions called from head_64.S.</p></li>
<li></li>
<li><p>The idt_table can’t be used that early because all the code modifying it is</p></li>
<li><p>in idt.c and can be instrumented by tracing or KASAN, which both don’t work</p></li>
<li><p>during early CPU bringup. Also the idt_table has the runtime vectors</p></li>
<li><p>configured which require certain CPU state to be setup already (like TSS),</p></li>
<li><p>which also hasn’t happened yet in early CPU bringup.</p></li>
</ul>
<p><a href="#id25"><span class="problematic" id="id26">*</span></a>/</p>
</dd>
</dl>
<p>static gate_desc bringup_idt_table[NUM_EXCEPTION_VECTORS] __page_aligned_data;</p>
<dl class="simple">
<dt>static struct desc_ptr bringup_idt_descr = {</dt><dd><p>.size           = (NUM_EXCEPTION_VECTORS * sizeof(gate_desc)) - 1,
.address        = 0, /* Set at runtime <a href="#id27"><span class="problematic" id="id28">*</span></a>/</p>
</dd>
</dl>
<p>};
static void set_bringup_idt_handler(gate_desc <a href="#id29"><span class="problematic" id="id30">*</span></a>idt, int n, void <a href="#id31"><span class="problematic" id="id32">*</span></a>handler)
{
#ifdef CONFIG_AMD_MEM_ENCRYPT</p>
<blockquote>
<div><p>struct idt_data data;
gate_desc desc;</p>
<p>init_idt_data(&amp;data, n, handler);
idt_init_desc(&amp;desc, &amp;data);
native_write_idt_entry(idt, n, &amp;desc);</p>
</div></blockquote>
<p>#endif
}</p>
<p>static void startup_64_load_idt(unsigned long physbase)
{</p>
<blockquote>
<div><p>struct desc_ptr <a href="#id33"><span class="problematic" id="id34">*</span></a>desc = fixup_pointer(&amp;bringup_idt_descr, physbase);
gate_desc <a href="#id35"><span class="problematic" id="id36">*</span></a>idt = fixup_pointer(bringup_idt_table, physbase);</p>
<dl>
<dt>if (IS_ENABLED(CONFIG_AMD_MEM_ENCRYPT)) {</dt><dd><p>void <a href="#id37"><span class="problematic" id="id38">*</span></a>handler;</p>
<p>/* VMM Communication Exception <a href="#id39"><span class="problematic" id="id40">*</span></a>/
handler = fixup_pointer(vc_no_ghcb, physbase);//未解析
set_bringup_idt_handler(idt, X86_TRAP_VC, handler);//未解析：注意X86_TRAP_VC:29 异常</p>
</dd>
</dl>
<p>}</p>
<p>desc-&gt;address = (unsigned long)idt;//到这儿只初始化了X86_TRAP_VC
native_load_idt(desc);//asm volatile(“lidt %0”::”m” (<a href="#id41"><span class="problematic" id="id42">*</span></a>dtr));</p>
</div></blockquote>
<p>}</p>
<p>#endif</p>
<p>}</p>
<p>//startup_64_setup_env  end</p>
<blockquote>
<div><p>popq    %rsi</p>
<p>/* Now switch to __KERNEL_CS so IRET works reliably <a href="#id43"><span class="problematic" id="id44">*</span></a>/
pushq   $__KERNEL_CS
leaq    .Lon_kernel_cs(%rip), %rax
pushq   %rax
lretq   // 跳转：rsp - sizeof(rax) : rsp,即__KERNEL_CS –&gt; CS,rax –&gt; IP</p>
</div></blockquote>
<p>//从此以后寻址就进入偏移了。</p>
<dl class="simple">
<dt>.Lon_kernel_cs:</dt><dd><p>UNWIND_HINT_EMPTY //调试用，编译内核时由objtool使用</p>
</dd>
</dl>
<p>#if 0
/*</p>
<blockquote>
<div><ul class="simple">
<li><p>In asm, there are two kinds of code: normal C-type callable functions and</p></li>
<li><p>the rest.  The normal callable functions can be called by other code, and</p></li>
<li><p>don’t do anything unusual with the stack.  Such normal callable functions</p></li>
<li><p>are annotated with the ENTRY/ENDPROC macros.  Most asm code falls in this</p></li>
<li><p>category.  In this case, no special debugging annotations are needed because</p></li>
<li><p>objtool can automatically generate the ORC data for the ORC unwinder to read</p></li>
<li><p>at runtime.</p></li>
<li></li>
<li><p>Anything which doesn’t fall into the above category, such as syscall and</p></li>
<li><p>interrupt handlers, tends to not be called directly by other functions, and</p></li>
<li><p>often does unusual non-C-function-type things with the stack pointer.  Such</p></li>
<li><p>code needs to be annotated such that objtool can understand it.  The</p></li>
<li><p>following CFI hint macros are for this type of code.</p></li>
<li></li>
<li><p>These macros provide hints to objtool about the state of the stack at each</p></li>
<li><p>instruction.  Objtool starts from the hints and follows the code flow,</p></li>
<li><p>making automatic CFI adjustments when it sees pushes and pops, filling out</p></li>
<li><p>the debuginfo as necessary.  It will also warn if it sees any</p></li>
<li><p>inconsistencies.</p></li>
</ul>
<p><a href="#id45"><span class="problematic" id="id46">*</span></a>/</p>
</div></blockquote>
<p>.macro UNWIND_HINT sp_reg:req sp_offset=0 type:req end=0
.Lunwind_hint_ip_&#64;:</p>
<blockquote>
<div><dl class="simple">
<dt>.pushsection .discard.unwind_hints  //就是在这个节中加入这么一段信息</dt><dd><p>/* struct unwind_hint <a href="#id47"><span class="problematic" id="id48">*</span></a>/
.long .Lunwind_hint_ip_&#64; - .
.short sp_offset
.byte sp_reg
.byte type
.byte end
.balign 4</p>
</dd>
</dl>
<p>.popsection</p>
</div></blockquote>
<p>.endm</p>
<dl class="simple">
<dt>.macro UNWIND_HINT_EMPTY</dt><dd><p>UNWIND_HINT sp_reg=ORC_REG_UNDEFINED type=UNWIND_HINT_TYPE_CALL end=1  //针对ORC专门来一段</p>
</dd>
</dl>
<p>.endm</p>
<p>#endif//end</p>
<blockquote>
<div><blockquote>
<div><dl class="simple">
<dt>/* Sanitize CPU configuration</dt><dd><ul class="simple">
<li><p>This is a common code for verification whether CPU supports</p></li>
</ul>
</dd>
</dl>
</div></blockquote>
<ul class="simple">
<li><p>long mode and SSE or not. It is not called directly instead this</p></li>
<li><p>file is included at various places and compiled in that context.</p></li>
<li><p>This file is expected to run in 32bit code.  Currently:</p></li>
<li></li>
<li><p>arch/x86/boot/compressed/head_64.S: Boot cpu verification</p></li>
<li><p>arch/x86/kernel/trampoline_64.S: secondary processor verification</p></li>
<li><p>arch/x86/kernel/head_32.S: processor startup</p></li>
<li></li>
<li><p>verify_cpu, returns the status of longmode and SSE in register %eax.</p></li>
<li><p>0: Success    1: Failure</p></li>
<li></li>
<li><p>On Intel, the XD_DISABLE flag will be cleared as a side-effect.</p></li>
<li></li>
<li><p>The caller needs to check for the error code and take the action</p></li>
<li><p>appropriately. Either display a message or halt.</p></li>
</ul>
<dl>
<dt><a href="#id49"><span class="problematic" id="id50">*</span></a>/</dt><dd><p><a href="#id51"><span class="problematic" id="id52">*</span></a>/
call verify_cpu</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Perform pagetable fixups. Additionally, if SME is active, encrypt</p></li>
<li><p>the kernel and retrieve the modifier (SME encryption mask if SME</p></li>
<li><p>is active) to be added to the initial pgdir entry that will be</p></li>
<li><p>programmed into CR3.</p></li>
</ul>
<p><a href="#id53"><span class="problematic" id="id54">*</span></a>/</p>
</dd>
</dl>
<p>leaq    _text(%rip), %rdi
pushq   %rsi
call    __startup_64</p>
</dd>
</dl>
</div></blockquote>
<p>#if 0 //__startup_64 start
/* Code in __startup_64() can be relocated during execution, but the compiler</p>
<blockquote>
<div><ul class="simple">
<li><p>doesn’t have to generate PC-relative relocations when accessing globals from</p></li>
<li><p>that function. Clang actually does not generate them, which leads to</p></li>
<li><p>boot-time crashes. To work around this problem, every global pointer must</p></li>
<li><p>be adjusted using fixup_pointer().</p></li>
</ul>
<p><a href="#id55"><span class="problematic" id="id56">*</span></a>/</p>
<dl>
<dt>unsigned long __head __startup_64(unsigned long physaddr,struct boot_params <a href="#id57"><span class="problematic" id="id58">*</span></a>bp) //参数：rdi:_text,rsi:boot_params</dt><dd><p>{
unsigned long vaddr, vaddr_end;
unsigned long load_delta, <a href="#id59"><span class="problematic" id="id60">*</span></a>p;
unsigned long pgtable_flags;
pgdval_t <a href="#id61"><span class="problematic" id="id62">*</span></a>pgd;
p4dval_t <a href="#id63"><span class="problematic" id="id64">*</span></a>p4d;
pudval_t <a href="#id65"><span class="problematic" id="id66">*</span></a>pud;
pmdval_t <a href="#id67"><span class="problematic" id="id68">*</span></a>pmd, pmd_entry;
pteval_t <a href="#id69"><span class="problematic" id="id70">*</span></a>mask_ptr;
bool la57;
int i;
unsigned int <a href="#id71"><span class="problematic" id="id72">*</span></a>next_pgt_ptr;</p>
<p>la57 = check_la57_support(physaddr);//if l5支持</p>
<p>/* Is the address too large? <a href="#id73"><span class="problematic" id="id74">*</span></a>/
if (physaddr &gt;&gt; MAX_PHYSMEM_BITS) //MAX_PHYSMEM_BITS:(pgtable_l5_enabled() ? 52 :46),超过就卡死了</p>
<blockquote>
<div><p>for (;;);</p>
</div></blockquote>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Compute the delta between the address I am compiled to run at</p></li>
<li><p>and the address I am actually running at.</p></li>
</ul>
<p><a href="#id75"><span class="problematic" id="id76">*</span></a>/</p>
</dd>
</dl>
<p>load_delta = physaddr - (unsigned long)(_text - __START_KERNEL_map); //引导加载与内核镜像中定义的差异？</p>
<p>/* Is the address not 2M aligned? <em>/
if (load_delta &amp; ~PMD_PAGE_MASK) /</em> 2M对齐，否则死寻话 <a href="#id77"><span class="problematic" id="id78">*</span></a>/</p>
<blockquote>
<div><p>for (;;);</p>
</div></blockquote>
<p>/* Activate Secure Memory Encryption (SME) if supported and enabled <a href="#id79"><span class="problematic" id="id80">*</span></a>/
sme_enable(bp);//sme/sev判断;</p>
<p>/* Include the SME encryption mask in the fixup value <a href="#id81"><span class="problematic" id="id82">*</span></a>/
load_delta += sme_get_me_mask();//所以？这个是什么个意思？</p>
<p>/* Fixup the physical addresses in the page table <a href="#id83"><span class="problematic" id="id84">*</span></a>/</p>
<p>pgd = fixup_pointer(&amp;early_top_pgt, physaddr);</p>
</dd>
</dl>
</div></blockquote>
<p>#if 0 early_top_pgt start</p>
<dl class="simple">
<dt>SYM_DATA_START_PTI_ALIGNED(early_top_pgt)</dt><dd><p>.fill   512,8,0  // 512 * 8 = 4KB
.fill   PTI_USER_PGD_FILL,8,0 // CONFIG_PAGE_TABLE_ISOLATION?</p>
</dd>
</dl>
<p>SYM_DATA_END(early_top_pgt)</p>
<p>#endif early_top_pgt end</p>
<blockquote>
<div><p>p = pgd + pgd_index(__START_KERNEL_map); //#define pgd_index(a)  (((a) &gt;&gt; PGDIR_SHIFT) &amp; (PTRS_PER_PGD - 1))  //pgd + 页号 ==&gt;地址单元
if (la57)</p>
<blockquote>
<div><p><a href="#id85"><span class="problematic" id="id86">*</span></a>p = (unsigned long)level4_kernel_pgt;//存放level4_kernel_pgt地址</p>
</div></blockquote>
<dl class="simple">
<dt>else</dt><dd><p><a href="#id87"><span class="problematic" id="id88">*</span></a>p = (unsigned long)level3_kernel_pgt;//存放level3_kernel_pgt地址</p>
</dd>
</dl>
<p><a href="#id89"><span class="problematic" id="id90">*</span></a>p += _PAGE_TABLE_NOENC - __START_KERNEL_map + load_delta;</p>
<dl class="simple">
<dt>if (la57) {</dt><dd><p>p4d = fixup_pointer(&amp;level4_kernel_pgt, physaddr);
p4d[511] += load_delta;</p>
</dd>
</dl>
<p>}</p>
<p>pud = fixup_pointer(&amp;level3_kernel_pgt, physaddr);
pud[510] += load_delta;
pud[511] += load_delta;</p>
<p>pmd = fixup_pointer(level2_fixmap_pgt, physaddr);
for (i = FIXMAP_PMD_TOP; i &gt; FIXMAP_PMD_TOP - FIXMAP_PMD_NUM; i–)</p>
<blockquote>
<div><p>pmd[i] += load_delta;</p>
</div></blockquote>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Set up the identity mapping for the switchover.  These</p></li>
<li><p>entries should <em>NOT</em> have the global bit set!  This also</p></li>
<li><p>creates a bunch of nonsense entries but that is fine –</p></li>
<li><p>it avoids problems around wraparound.</p></li>
</ul>
<p><a href="#id91"><span class="problematic" id="id92">*</span></a>/</p>
</dd>
</dl>
<p>next_pgt_ptr = fixup_pointer(&amp;next_early_pgt, physaddr);
pud = fixup_pointer(early_dynamic_pgts[(<a href="#id93"><span class="problematic" id="id94">*</span></a>next_pgt_ptr)++], physaddr);
pmd = fixup_pointer(early_dynamic_pgts[(<a href="#id95"><span class="problematic" id="id96">*</span></a>next_pgt_ptr)++], physaddr);</p>
<p>pgtable_flags = _KERNPG_TABLE_NOENC + sme_get_me_mask();</p>
<dl>
<dt>if (la57) {</dt><dd><dl class="simple">
<dt>p4d = fixup_pointer(early_dynamic_pgts[(<a href="#id97"><span class="problematic" id="id98">*</span></a>next_pgt_ptr)++],</dt><dd><p>physaddr);</p>
</dd>
</dl>
<p>i = (physaddr &gt;&gt; PGDIR_SHIFT) % PTRS_PER_PGD;
pgd[i + 0] = (pgdval_t)p4d + pgtable_flags;
pgd[i + 1] = (pgdval_t)p4d + pgtable_flags;</p>
<p>i = physaddr &gt;&gt; P4D_SHIFT;
p4d[(i + 0) % PTRS_PER_P4D] = (pgdval_t)pud + pgtable_flags;
p4d[(i + 1) % PTRS_PER_P4D] = (pgdval_t)pud + pgtable_flags;</p>
</dd>
<dt>} else {</dt><dd><p>i = (physaddr &gt;&gt; PGDIR_SHIFT) % PTRS_PER_PGD;
pgd[i + 0] = (pgdval_t)pud + pgtable_flags;
pgd[i + 1] = (pgdval_t)pud + pgtable_flags;</p>
</dd>
</dl>
<p>}</p>
<p>i = physaddr &gt;&gt; PUD_SHIFT;
pud[(i + 0) % PTRS_PER_PUD] = (pudval_t)pmd + pgtable_flags;
pud[(i + 1) % PTRS_PER_PUD] = (pudval_t)pmd + pgtable_flags;</p>
<p>pmd_entry = __PAGE_KERNEL_LARGE_EXEC &amp; ~_PAGE_GLOBAL;
/* Filter out unsupported __PAGE_KERNEL_* bits: <a href="#id99"><span class="problematic" id="id100">*</span></a>/
mask_ptr = fixup_pointer(&amp;__supported_pte_mask, physaddr);
pmd_entry &amp;= <a href="#id101"><span class="problematic" id="id102">*</span></a>mask_ptr;
pmd_entry += sme_get_me_mask();
pmd_entry +=  physaddr;</p>
<dl>
<dt>for (i = 0; i &lt; DIV_ROUND_UP(_end - _text, PMD_SIZE); i++) {</dt><dd><p>int idx = i + (physaddr &gt;&gt; PMD_SHIFT);</p>
<p>pmd[idx % PTRS_PER_PMD] = pmd_entry + i * PMD_SIZE;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Fixup the kernel text+data virtual addresses. Note that</p></li>
<li><p>we might write invalid pmds, when the kernel is relocated</p></li>
<li><p>cleanup_highmap() fixes this up along with the mappings</p></li>
<li><p>beyond _end.</p></li>
<li></li>
<li><p>Only the region occupied by the kernel image has so far</p></li>
<li><p>been checked against the table of usable memory regions</p></li>
<li><p>provided by the firmware, so invalidate pages outside that</p></li>
<li><p>region. A page table entry that maps to a reserved area of</p></li>
<li><p>memory would allow processor speculation into that area,</p></li>
<li><p>and on some hardware (particularly the UV platform) even</p></li>
<li><p>speculative access to some reserved areas is caught as an</p></li>
<li><p>error, causing the BIOS to halt the system.</p></li>
</ul>
<p><a href="#id103"><span class="problematic" id="id104">*</span></a>/</p>
</dd>
</dl>
<p>pmd = fixup_pointer(level2_kernel_pgt, physaddr);</p>
<p>/* invalidate pages before the kernel image <a href="#id105"><span class="problematic" id="id106">*</span></a>/
for (i = 0; i &lt; pmd_index((unsigned long)_text); i++)</p>
<blockquote>
<div><p>pmd[i] &amp;= ~_PAGE_PRESENT;</p>
</div></blockquote>
<p>/* fixup pages that are part of the kernel image <a href="#id107"><span class="problematic" id="id108">*</span></a>/
for (; i &lt;= pmd_index((unsigned long)_end); i++)</p>
<blockquote>
<div><dl class="simple">
<dt>if (pmd[i] &amp; _PAGE_PRESENT)</dt><dd><p>pmd[i] += load_delta;</p>
</dd>
</dl>
</div></blockquote>
<p>/* invalidate pages after the kernel image <a href="#id109"><span class="problematic" id="id110">*</span></a>/
for (; i &lt; PTRS_PER_PMD; i++)</p>
<blockquote>
<div><p>pmd[i] &amp;= ~_PAGE_PRESENT;</p>
</div></blockquote>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Fixup phys_base - remove the memory encryption mask to obtain</p></li>
<li><p>the true physical address.</p></li>
</ul>
<p><a href="#id111"><span class="problematic" id="id112">*</span></a>/</p>
</dd>
</dl>
<p><a href="#id113"><span class="problematic" id="id114">*</span></a>fixup_long(&amp;phys_base, physaddr) += load_delta - sme_get_me_mask();</p>
<p>/* Encrypt the kernel and related (if SME is active) <a href="#id115"><span class="problematic" id="id116">*</span></a>/
sme_encrypt_kernel(bp);</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Clear the memory encryption mask from the .bss..decrypted section.</p></li>
<li><p>The bss section will be memset to zero later in the initialization so</p></li>
<li><p>there is no need to zero it after changing the memory encryption</p></li>
<li><p>attribute.</p></li>
</ul>
<p><a href="#id117"><span class="problematic" id="id118">*</span></a>/</p>
</dd>
<dt>if (mem_encrypt_active()) {</dt><dd><p>vaddr = (unsigned long)__start_bss_decrypted;
vaddr_end = (unsigned long)__end_bss_decrypted;
for (; vaddr &lt; vaddr_end; vaddr += PMD_SIZE) {</p>
<blockquote>
<div><p>i = pmd_index(vaddr);
pmd[i] -= sme_get_me_mask();</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Return the SME encryption mask (if SME is active) to be used as a</p></li>
<li><p>modifier for the initial pgdir entry programmed into CR3.</p></li>
</ul>
<p><a href="#id119"><span class="problematic" id="id120">*</span></a>/</p>
</dd>
</dl>
<p>return sme_get_me_mask();</p>
</div></blockquote>
<p>}</p>
<p>#endif // __startup_64 end</p>
<blockquote>
<div><p>popq    %rsi</p>
<p>/* Form the CR3 value being sure to include the CR3 modifier <a href="#id121"><span class="problematic" id="id122">*</span></a>/
addq    $(early_top_pgt - __START_KERNEL_map), %rax
jmp 1f</p>
</div></blockquote>
<p>SYM_CODE_END(startup_64)</p>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Rachel.Sun.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>